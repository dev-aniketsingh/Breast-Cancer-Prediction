---
title: "Term Project - Predictive Modeling"
output:
  pdf_document: default
  md_document:
    variant: gfm
  html_document:
    df_print: paged
---
Loding important packages 
```{r}
library(readr,  warn.conflicts=F)
library(RColorBrewer,  warn.conflicts=F) #Rcolorbrewer palette
library(corrplot,  warn.conflicts=F)
library(ggcorrplot,  warn.conflicts=F)
library(plotly,  warn.conflicts=F)
library(ggplot2, warn.conflicts=F)
library(reshape, warn.conflicts=F)
library(viridis, warn.conflicts=F)
library(tidyverse, warn.conflicts=F)
library(hrbrthemes, warn.conflicts=F)
library(psych, warn.conflicts=F)
library(class, warn.conflicts=F)
library(caret, warn.conflicts = F)
library(DescTools)
library(sjPlot)
set.seed(123456789)
```


Importing Dataset
```{r}
data <- read.csv("~/Breast-Cancer-Prediction/data/data.csv",  header=T)
cancerData <- read.csv("~/Breast-Cancer-Prediction/data/data.csv",  header=T)

```

Looking at dataset
```{r}
head(data)
```

Columns in dataset
```{r}
colnames(data)
```

Checking for null values
```{r}
lapply(data,function(x) { length(which(is.na(x)))})
```

We can notice, that there seems to be three category in dataset. They're: 
mean, se and worst

DATA WRANGLING 
Deleting X column as it seems to be a mistake while importing the dataset 
```{r}
drops <- c("X")
data <- data[ , !(names(data) %in% drops)]
```

```{r}
lapply(data,function(x) { length(which(is.na(x)))})
```


\
As we can notice now we do not have any missing data
\

\
Let's looking into correlation matrix to see correlation  between all the variables
\
```{r}
matrixData <- cor(data[sapply(data,is.numeric)], method="pearson")
# Rcolorbrewer palette
coul <- colorRampPalette(brewer.pal(8, "PiYG"))(25)
heatmap(matrixData, scale="column", col = coul)

```

```{r}
corrplot(matrixData, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)
```

```{r}
#data <- sapply(data,is.numeric)
data.mean <- cor(data[,c(3:12)],method="pearson")
data.se <- cor(data[,c(13:22)],method="pearson")
data.worst <- cor(data[,c(23:32)],method="pearson")


corrplot(data.mean, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)



corrplot(data.se, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)



corrplot(data.worst, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)
```


\
```{r}
table(data$diagnosis)
prop.table(table(data$diagnosis))*100
```

```{r}
ggplot(data, aes(x=as.factor(diagnosis), fill=as.factor(diagnosis) )) + 
  geom_bar( ) +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position="none")
```


```{r}
pairs.panels(data[,c(3:12)], main="Cancer Mean")
pairs.panels(data[,c(13:22)], main="Cancer SE")
pairs.panels(data[,c(23:32)], main="Cancer Worst")

```
```{r}
ggplot(data, aes(x = diagnosis,
y = radius_mean)) + geom_violin(fill = "cornflowerblue") + geom_boxplot(width = .01,
fill = "orange", outlier.color = "orange", outlier.size = 2) +
labs(title = "Radius Mean distribution by diagnosis")
```
```{r}
ggplot(data, aes(x = diagnosis,
y = radius_se)) + geom_violin(fill = "cornflowerblue") + geom_boxplot(width = .01,
fill = "orange", outlier.color = "orange", outlier.size = 2) +
labs(title = "Radius Se distribution by diagnosis")
```
```{r}
ggplot(data, aes(x = diagnosis,
y = radius_worst)) + geom_violin(fill = "cornflowerblue") + geom_boxplot(width = .01,
fill = "orange", outlier.color = "orange", outlier.size = 3) +
labs(title = "Radius Wprst distribution by diagnosis")
```
\
Let's split the data now to see how tumors differ for M and B
\
```{r}
dataNew <- split(data, data$diagnosis)
dataB <- dataNew$B
dataM <- dataNew$M
```
\
Now we have two different datasets for B and M
\
####(I will do this work later, I can't find perfect visualization technique for this)


Model Building 

```{r}
str(cancerData)
cancerData <- select(cancerData, -id, -X)
cancerData$diagnosis<- as.numeric(as.factor(cancerData$diagnosis))
 
library(kernlab)
ind <- sample(1:dim(cancerData)[1],170)
train <- cancerData[-ind, ]
test <- cancerData[ind, ]
```


```{r}
library(e1071)

svmfit = svm(diagnosis~ ., data = train, kernel = "linear", cost = 5, scale = FALSE)
tune.out <- tune(svm, diagnosis~., data = train, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
# extract the best model
(bestmod <- tune.out$best.model)
```

```{r}
prediction <- predict(bestmod,test)
prediction_train <- predict(bestmod,train)

```

```{r}
library(Metrics)
cor(test$diagnosis,prediction)*100
cmBest = table(test[,1], prediction)
#cm
cm2Best = table(train[,1], prediction_train )
#cm2

```


```{r}
classifier = svm(formula = diagnosis ~ .,
                 data = train,
                 type = 'C-classification',
                 kernel = 'linear')

y_pred = predict(classifier, test)
y_train_pred = predict(classifier, train)

```

```{r}
cmBEST = table(test[,1], y_pred)
cmBEST
cm2BEST = table(train[,1], y_train_pred )
cm2BEST

#cor(test$diagnosis,y_pred)*100

```
#7 inccorect in train and 2 incorrect in test

```{r}
library(caret) 
confusionMatrix(cmBEST)
confusionMatrix(cm2BEST)

```
Model accuracy of 98% obtained on test set and also 98% on train set.


```{r}

plot(classifier , train, radius_mean~texture_mean )

```

```{r}
train
plot(classifier , train, perimeter_mean~area_mean )
plot(classifier , train, compactness_mean~concavity_mean )
plot(classifier , train, radius_se~radius_mean )

```

