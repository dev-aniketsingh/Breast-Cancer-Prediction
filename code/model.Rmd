---
title: "Term Project - Predictive Modeling"
output:
  pdf_document: default
  md_document:
    variant: gfm
  html_document:
    df_print: paged
    
---
Loding important packages 
```{r}
library(readr,  warn.conflicts=F)
library(RColorBrewer,  warn.conflicts=F) #Rcolorbrewer palette
library(corrplot,  warn.conflicts=F)
library(ggcorrplot,  warn.conflicts=F)
library(plotly,  warn.conflicts=F)
library(ggplot2, warn.conflicts=F)
library(reshape, warn.conflicts=F)
library(viridis, warn.conflicts=F)
library(tidyverse, warn.conflicts=F)
library(hrbrthemes, warn.conflicts=F)
library(psych, warn.conflicts=F)
library(class, warn.conflicts=F)
library(caret, warn.conflicts = F)
library(DescTools)
library(sjPlot)
set.seed(123456789)
```


Importing Dataset
```{r}
data <- read.csv("~/Breast-Cancer-Prediction/data/data.csv",  header=T)
cancerData <- read.csv("~/Breast-Cancer-Prediction/data/data.csv",  header=T)

```

Looking at dataset
```{r}
head(data)
```

Columns in dataset
```{r}
colnames(data)
```

Checking for null values
```{r}
lapply(data,function(x) { length(which(is.na(x)))})
```

We can notice, that there seems to be three category in dataset. They're: 
mean, se and worst

DATA WRANGLING 
Deleting X column as it seems to be a mistake while importing the dataset 
```{r}
drops <- c("X")
data <- data[ , !(names(data) %in% drops)]
```

```{r}
lapply(data,function(x) { length(which(is.na(x)))})
```


\
As we can notice now we do not have any missing data
\

\
Let's looking into correlation matrix to see correlation  between all the variables
\
```{r}
matrixData <- cor(data[sapply(data,is.numeric)], method="pearson")
# Rcolorbrewer palette
coul <- colorRampPalette(brewer.pal(8, "PiYG"))(25)
heatmap(matrixData, scale="column", col = coul)

```

```{r}
corrplot(matrixData, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)
```

```{r}
#data <- sapply(data,is.numeric)
data.mean <- cor(data[,c(3:12)],method="pearson")
data.se <- cor(data[,c(13:22)],method="pearson")
data.worst <- cor(data[,c(23:32)],method="pearson")


corrplot(data.mean, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)



corrplot(data.se, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)



corrplot(data.worst, tl.col = "black", order = "hclust", hclust.method = "average", addrect = 4, tl.cex = 0.7)
```


\
```{r}
table(data$diagnosis)
prop.table(table(data$diagnosis))*100
```

```{r}
ggplot(data, aes(x=as.factor(diagnosis), fill=as.factor(diagnosis) )) + 
  geom_bar( ) +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position="none")
```


```{r}
pairs.panels(data[,c(3:12)], main="Cancer Mean")
pairs.panels(data[,c(13:22)], main="Cancer SE")
pairs.panels(data[,c(23:32)], main="Cancer Worst")

```
```{r}
ggplot(data, aes(x = diagnosis,
y = radius_mean)) + geom_violin(fill = "cornflowerblue") + geom_boxplot(width = .01,
fill = "orange", outlier.color = "orange", outlier.size = 2) +
labs(title = "Radius Mean distribution by diagnosis")
```
```{r}
ggplot(data, aes(x = diagnosis,
y = radius_se)) + geom_violin(fill = "cornflowerblue") + geom_boxplot(width = .01,
fill = "orange", outlier.color = "orange", outlier.size = 2) +
labs(title = "Radius Se distribution by diagnosis")
```
```{r}
ggplot(data, aes(x = diagnosis,
y = radius_worst)) + geom_violin(fill = "cornflowerblue") + geom_boxplot(width = .01,
fill = "orange", outlier.color = "orange", outlier.size = 3) +
labs(title = "Radius Wprst distribution by diagnosis")
```
\
Let's split the data now to see how tumors differ for M and B
\
```{r}
dataNew <- split(data, data$diagnosis)
dataB <- dataNew$B
dataM <- dataNew$M
```
\
Now we have two different datasets for B and M
\
####(I will do this work later, I can't find perfect visualization technique for this)


Model Building 

```{r}
cancerData <- select(cancerData, -id, -X)
cancerData$diagnosis<- as.numeric(as.factor(cancerData$diagnosis))
 
library(kernlab)
ind <- sample(1:dim(cancerData)[1],170)
train <- cancerData[-ind, ]
test <- cancerData[ind, ]
```


```{r}
library(e1071)

svmfit = svm(diagnosis~ ., data = train, kernel = "linear", cost = 5, scale = FALSE)
tune.out <- tune(svm, diagnosis~., data = train, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
# extract the best model
(bestmod <- tune.out$best.model)
```

```{r}
prediction <- predict(bestmod,test)
prediction_train <- predict(bestmod,train)

```

```{r}
library(Metrics)
cor(test$diagnosis,prediction)*100
cmBest = table(test[,1], prediction)
#cm
cm2Best = table(train[,1], prediction_train )
#cm2

```


```{r}
classifier = svm(formula = diagnosis ~ .,
                 data = train,
                 type = 'C-classification',
                 kernel = 'linear')
y_pred = predict(classifier, test)
y_train_pred = predict(classifier, train)

```


```{r}
summary (classifier )

```



```{r}
cmBEST = table(test[,1], y_pred)
cm2BEST = table(train[,1], y_train_pred )

#cor(test$diagnosis,y_pred)*100

```
#7 inccorect in train and 2 incorrect in test

```{r}
library(caret) 
confusionMatrix(cmBEST)
confusionMatrix(cm2BEST)
```
Model accuracy of 98% obtained on test set and also 98% on train set. 

###Code from stackoverflow 
###https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package/42940553

```{r}
cm <- confusionMatrix(cmBEST)
draw_confusion_matrix <- function(cm) {

  total <- sum(cm$table)
  res <- as.numeric(cm$table)

  # Generate color gradients. Palettes come from RColorBrewer.
  greenPalette <- c("#F7FCF5","#E5F5E0","#C7E9C0","#A1D99B","#74C476","#41AB5D","#238B45","#006D2C","#00441B")
  redPalette <- c("#FFF5F0","#FEE0D2","#FCBBA1","#FC9272","#FB6A4A","#EF3B2C","#CB181D","#A50F15","#67000D")
  getColor <- function (greenOrRed = "green", amount = 0) {
    if (amount == 0)
      return("#FFFFFF")
    palette <- greenPalette
    if (greenOrRed == "red")
      palette <- redPalette
    colorRampPalette(palette)(100)[10 + ceiling(90 * amount / total)]
  }

  # set the basic layout
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  classes = colnames(cm$table)
  rect(150, 430, 240, 370, col=getColor("green", res[1]))
  text(195, 435, classes[1], cex=1.2)
  rect(250, 430, 340, 370, col=getColor("red", res[3]))
  text(295, 435, classes[2], cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col=getColor("red", res[2]))
  rect(250, 305, 340, 365, col=getColor("green", res[4]))
  text(140, 400, classes[1], cex=1.2, srt=90)
  text(140, 335, classes[2], cex=1.2, srt=90)

  # add in the cm results
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  
draw_confusion_matrix(cm)

```


```{r}

plot(classifier , train, radius_mean~texture_mean )
```

```{r}
plot(classifier , train, perimeter_mean~area_mean )
plot(classifier , train, compactness_mean~concavity_mean )
plot(classifier , train, radius_se~radius_mean )

```

```{r}
df_t_m %>%
  ggplot(aes(fill=diagnosis, y=value, x=features)) + 
    geom_violin(alpha=0.5,width = 0.5 ) +
    xlab("Features") +
    ylab("Value") +
    ylim(-6,6) +
    theme_minimal(base_size = 12) +
    theme(axis.text.x = element_text(size = 14)) +
    labs(title="Mean values distribution")

fig1 <- ggplotly(p1)
```

